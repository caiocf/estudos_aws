# Terraform â€” AWS Glue Data Catalog (SOR) com S3 â†’ SQS (Event Mode)

Infraestrutura como cÃ³digo (IaC) em **Terraform** para provisionar um â€œmini data lakeâ€ na AWS com:

- **Amazon S3** (camada SOR / landing)
- **AWS Glue Data Catalog** (database + tabela(s) via crawler)
- **AWS Glue Crawler** em **modo incremental por eventos** (*S3 Event Notifications* â†’ **SQS**)  
- **IAM** (role e policies mÃ­nimas para o crawler)
- Upload de um **CSV de exemplo** para validar o fluxo end-to-end


> **Importante:** `event_queue_arn` **nÃ£o dispara** o crawler automaticamente. Ele apenas habilita o **modo por eventos**, no qual o crawler **consome mensagens da SQS durante uma execuÃ§Ã£o** (por *schedule* ou execuÃ§Ã£o manual) para identificar o que mudou e evitar varrer todo o S3.
> Se vocÃª adicionar um novo CSV **dentro de uma partiÃ§Ã£o jÃ¡ conhecida** e o **schema** permanecer igual, ele poderÃ¡ ser lido normalmente pelos consumidores (ex.: Athena/Spark) pelo `LOCATION` da tabela â€” sem necessidade de rodar o crawler.
> VocÃª normalmente precisa executar o crawler quando houver **criaÃ§Ã£o de novas partiÃ§Ãµes** (ex.: novo `dt=.../`) que precisam ser registradas no catÃ¡logo (a menos que vocÃª use *partition projection*), ou quando houver **mudanÃ§as de schema** (ex.: adicionar coluna, remover coluna, alterar tipo).

---

## ğŸ§­ VisÃ£o geral

O objetivo Ã© manter o **Glue Data Catalog** atualizado a partir de arquivos CSV no S3:

1. Um arquivo Ã© enviado para o S3 (ex.: `customers/customers_1.csv` dentro de partiÃ§Ãµes por `ano/mes/dia`)
2. O S3 publica um evento na fila **SQS**
3. Quando o **Glue Crawler** roda, ele lÃª a **SQS** para descobrir o que mudou e atualizar o catÃ¡logo

---

## ğŸ—ï¸ Arquitetura (alto nÃ­vel)

```
Upload CSV
   â”‚
   â–¼
S3 bucket (SOR) â”€â”€(Event Notification)â”€â”€â–º SQS (event queue)
   â”‚                                         â”‚
   â”‚                                         â–¼
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Glue Crawler (CRAWL_EVENT_MODE) â”€â”€â–º Glue Data Catalog (DB/Tables)
```

---

## ğŸ“¦ O que este projeto cria

### S3
- Bucket SOR (nome por padrÃ£o: `corp-sor-sa-east-1-<account_id>` â€” pode ser sobrescrito por variÃ¡vel)
- **Public Access Block** habilitado
- Criptografia server-side padrÃ£o (`AES256`)
- Upload de amostra: `customers_1.csv` em um caminho particionado:
  - `customers/ano=2023/mes=10/dia=28/customers_1.csv`

### SQS
- Fila **Standard** para eventos do S3
- **Queue policy** permitindo:
  - `s3.amazonaws.com` fazer `SendMessage` (restrito por `SourceArn` do bucket e `SourceAccount`)
  - a role do Glue consumir a fila (`ReceiveMessage`, `DeleteMessage`, etc.)

### Glue
- `aws_glue_catalog_database` (DB do SOR)
- `aws_glue_crawler` apontando para o prefixo do dataset no S3
- `recrawl_policy` em **`CRAWL_EVENT_MODE`** (incremental por eventos)
- `schema_change_policy`:
  - `update_behavior = "UPDATE_IN_DATABASE"` (atualiza metadados no catÃ¡logo quando houver mudanÃ§as)
  - `delete_behavior = "LOG"` (nÃ£o apaga metadados; apenas registra em log)

### IAM
- Role do crawler com trust para `glue.amazonaws.com`
- Anexo da policy gerenciada `AWSGlueServiceRole`
- Policies adicionais para:
  - Ler/listar o bucket/prefixo do S3
  - Consumir mensagens da fila SQS

---

## âœ… PrÃ©-requisitos

- Terraform instalado (o projeto define `required_version` em `version.tf`)
- AWS CLI configurada (ou variÃ¡veis de ambiente com credenciais)
- PermissÃµes na conta AWS para criar S3/SQS/IAM/Glue

---

## ğŸš€ Como executar

```bash
terraform init
terraform plan
terraform apply
```

ApÃ³s o `apply`, vocÃª pode:

- Aguardar o **schedule** (de 15 em 15 minutos) do crawler (de acordo com o estiver configurado no seu `main.tf`), **ou**
- Iniciar manualmente no Console do Glue, **ou**
- Via CLI:

```bash
aws glue start-crawler --name <NOME_DO_CRAWLER>
```

---

## ğŸ”§ VariÃ¡veis principais

As variÃ¡veis ficam em `variable.tf`. As mais comuns:

- `aws_region`: regiÃ£o do provider AWS
- `sor_s3bucket`: **opcional** â€” sobrescreve o nome do bucket SOR
- `sor_db_name_source`: nome do Glue Catalog Database
- `sor_table_name`: prefixo/pasta do dataset (padrÃ£o: `customers`)
- `control_account`: opcional (ID de conta de controle, se vocÃª estiver simulando multi-account)

## ğŸ“¤ Outputs

ApÃ³s `terraform apply`, veja:

- `bucket_name`
- `queue_url`
- `queue_arn`

---

## ğŸ§ª Como validar rapidamente

1. Abra o bucket e confirme o arquivo de amostra em:
   `customers/ano=2023/mes=10/dia=28/customers_1.csv`
2. Verifique se a SQS recebeu mensagens (mÃ©tricas/console).
3. Execute o crawler e confirme no **Glue Data Catalog**:
   - Database criado
   - Tabela(s) criada(s)
   - PartiÃ§Ãµes detectadas (dependendo da classificaÃ§Ã£o e do crawler)

---

## ğŸ§¹ Cleanup

```bash
terraform destroy
```

---

